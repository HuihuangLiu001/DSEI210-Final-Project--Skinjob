{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "image_numpy_convertor.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jn5p1P6Nv3hg",
        "outputId": "73e05341-aa3c-43bf-8666-9fe611c280db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ],
      "source": [
        "!pwd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['KAGGLE_CONFIG_DIR'] = \"/content\""
      ],
      "metadata": {
        "id": "MkF3QB4ZwuPs"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d surajghuwalewala/ham1000-segmentation-and-classification"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a8Tuo5Mjw0i-",
        "outputId": "095999a9-5c4a-4b19-9813-3a454f731b08"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /content/kaggle.json'\n",
            "Downloading ham1000-segmentation-and-classification.zip to /content\n",
            " 99% 2.57G/2.59G [00:25<00:00, 165MB/s]\n",
            "100% 2.59G/2.59G [00:25<00:00, 109MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/ham1000-segmentation-and-classification.zip"
      ],
      "metadata": {
        "id": "w_R3_eqIw5C_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np \n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.layers import Dense, Activation,Dropout,Conv2D, MaxPooling2D,BatchNormalization, Flatten\n",
        "from tensorflow.keras.optimizers import Adam, Adamax\n",
        "from tensorflow.keras.metrics import categorical_crossentropy\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Model, load_model, Sequential\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.pyplot import imshow"
      ],
      "metadata": {
        "id": "bkRPIhB4wvp4"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def img_np_convert(dataframe, image, h, w):\n",
        "  df = pd.read_csv(dataframe)\n",
        "  df['image'] = df['image'] +'.jpg'\n",
        "\n",
        "  labels=['MEL', 'NV', 'BCC', 'AKIEC', 'BKL', 'DF', 'VASC']\n",
        "  label_list=[]\n",
        "  for index, row in df.iterrows():\n",
        "      temp = list(row)\n",
        "      del temp[0]\n",
        "      index=np.argmax(temp)\n",
        "      label=labels[index]\n",
        "      label_list.append(label)\n",
        "  df['label']= label_list\n",
        "  df=df.drop(labels, axis=1)\n",
        "\n",
        "  sdir=image # main directory where data is stored\n",
        "  save_dir=r'./' # output directory where model will be saved\n",
        "  height=h  # image height\n",
        "  width=w   # image width\n",
        "  channels=3  # number of coloor channels\n",
        "  batch_size=40  # model batch size for training and evaluation\n",
        "  img_shape=(height, width, channels)\n",
        "  img_size=(height, width)\n",
        "\n",
        "  gen=ImageDataGenerator(rescale=1./255) \n",
        "\n",
        "  df_gen=gen.flow_from_dataframe( df, sdir, x_col='image', y_col='label', target_size=img_size, class_mode='categorical',\n",
        "                                      color_mode='rgb', shuffle=True, batch_size=batch_size)\n",
        "  images, labels = next(df_gen)\n",
        "  for x in range(250):\n",
        "    temp_images, temp_labels = next(df_gen)\n",
        "    images = np.concatenate((images, temp_images), axis=0)\n",
        "    labels = np.concatenate((labels, temp_labels), axis=0)\n",
        "  return images, labels"
      ],
      "metadata": {
        "id": "qudYc8mcONiw"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_path = '../content/GroundTruth.csv'\n",
        "image_path = r'../content/images'\n",
        "images, labels = img_np_convert(df_path, image_path, 32, 32)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aIJQ5e8oQd5E",
        "outputId": "77518d38-3542-4160-cac7-4494bd3436ef"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 10015 validated image filenames belonging to 7 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "images.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "teKiAjn4zYD3",
        "outputId": "c8f0ceff-fa68-4d5e-a95c-ff60b1fe6d47"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10015, 32, 32, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5S7m6nB0z7ns",
        "outputId": "e9519f3c-d777-4b7b-b643-a5c5be008aea"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10015, 7)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.save('images96_96', images)"
      ],
      "metadata": {
        "id": "Ey9vYDc3z_2G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.save('labels96_96', labels)"
      ],
      "metadata": {
        "id": "5BfFe-wn0NBN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}