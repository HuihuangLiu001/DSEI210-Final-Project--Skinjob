{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GML0uNJJC3Qr"
      },
      "source": [
        "#**Final Report**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FwicSKrEC_Xr"
      },
      "source": [
        "## Title: New Era Of Data Model Dermatology"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9PECsHfGDDOn"
      },
      "source": [
        "## Abstract\n",
        "Skin cancers are the development of abnormal skin cells that have acquired the ability to invade or spread to other parts of the body. They are the most commonly diagnosed cancer in the United States and many cases are preventable. Skin cancer greatly impacts the quality of life, from both medical and socioeconomics standpoint. It is expected that the skin cancer incidence rates will continue to trend upward as the societal population ages. Research has shown that skin cancer diagnostic accuracy is in the range of 67-75%, meaning that the remaining 25-33% of the skin cancers are either incorrectly diagnosed as eczema or another less serious disease. Ultimately, this problem would lead us to ask whether machine learning models can be designed and implemented to effectively classify if a patient developed skin cancer based on photographs of skin lesions on dermatologic slides. The main objective of our project is to develop models to classify skin lesions into seven categories and have a diagnostic accuracy that can consistently match or outperform human benchmarks by emphasizing on the recall and precision rate in detecting skin cancers. We want to obtain a higher F1 score for skin cancers, which is a metric that takes a harmonic mean between precision and recall, and it represents a better metric for an imbalanced dataset. Early skin malignancy detection is important because it helps save life. Till today, we still have limited screening methods and resources toward skin cancer in clinical settings and oftentimes if a skin malignancy is suggested, it has already transitioned into the late stage for the patient. Therefore, accurate skin cancer detection is the key, it will essentially improve survival rate, clinical outcome and quality of life for the patient. In the process of incorporating a series of machine learning techniques to help us build a model that can distinguish skin cancers from other skin lesion conditions. A convulsion neural network model was selected and built with the accuracy of matching human benchmark; lower end of the human benchmark can be achieved if 90 x 90 pixels images were used and higher end of the human benchmark can be achieved if 240 x 240 pixels images were used. Alongside, we also identified age and localization to be very effective features during model training. One versus rest is effective for basal cell carcinoma, but not melanoma. Additionally, it is worth noting that our data suffer from biases coming from skin lesions of lighter skin origin only, which can result in skewed outcomes and analytical errors if darker skin dermatologic images were introduced."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mia0pbMlDG1E"
      },
      "source": [
        "## Introduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gMgIG72EJDgo"
      },
      "source": [
        "The research question for this project is: can machine learning models be designed and implemented to effectively classify if a patient developed skin cancer based on photographs of skin lesions on dermatologic slides and have a diagnostic accuracy that can consistently match or outperform human benchmarks? Early skin malignancy detection is important because screening for earlier skin cancer detection remains limited in clinical settings, which leads to late stage diagnoses in most cases. Accurate skin cancer detection in patients by dermatologists and pathologists show improved survival, clinical outcomes, and quality of life. Research plan includes initial data cleaning and exploratory data analysis to investigate data patterns, anomalies, and to test hypotheses and to check assumptions with the help of summary statistics and graphical representations. We will develop basic linear and logistic models, SVM, DNN, CNN models. We did not achieve high linear and logistic model accuracy, CNN accuracy was higher than the DNN. SVM - still attempting. Data cleaning includes filling in missing age columns with the average for the age column, we also detected that the data labels are imbalanced due to the fact that skin cancers are rare occurrences relative to the overall general population. Therefore, initial data cleaning and preparation allows us to develop approaches in combating data imbalance, such as resampling techniques. The dataset we use is \"Skin Cancer MNIST: Ham10000\". Skin Cancer MNIST: HAM10000 is a dataset collected dermatoscopic images acquired from different populations. The dataset contains 10015 dermatoscopic image including a representative collection of all important diagnostic categories in the realm of pigmented lesions. We want to know if we can build an application that can distinguish the different skin condition utilizing machine learning.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TF9p6HZaDKsK"
      },
      "source": [
        "## Background\n",
        "\n",
        "Dermatoscopy is the predominant gold standard diagnostic technique that helps in the diagnosis of benign and malignant skin lesions in comparison to examination with the unaided eye(1). In one prior research work on the classification of skin tumors into malignant or benign using machine learning and deep learning models. Machine learning algorithms include logistic regression, linear discriminant analysis, k-nearest neighbors classifier, decision tree classifier and Gaussian naive Bayes, while deep learning models employed are either based on a custom Convolutional Neural Network model or leverage transfer learning via the use of pre-trained models (VGG16, Xception and ResNet50). Results showed that deep learning models, with accuracies up to 0.88, all outperform machine learning models. Ensemble learning of the machine learning models exhibit accuracies up to 0.75. Subsequently, they further assess the performance of machine learning and deep learning models by testing on a larger and more imbalanced dataset and metrics of 0.70 and 0.88 are obtained, respectively (2).\n",
        "\n",
        "Dermatoscopic images are great available source to train artificial neural networks to categorize the skin lesions automatically. Binder and his colleagues have long demonstrated such technique to differentiate melanomas from melanocytic nevi, dating back to 1994 (3). Interestingly, the study suffered from small sample size but managed to obtain promising results. Recent advancement in the complexity of neural networks in machine learning techniques is bringing hope that automated diagnostic systems will one day work synchronously or asynchronously with expertise skills to improve the diagnosis accuracy (4). Training of neural-network based diagnostic algorithms is functionally dependent on the number of annotated images, but the quantity of high quality and reliable dermatoscopic slides are limited or restricted to only a few classes of diseases (5). The ISIC archive is a collection of multiple databases. Because of permissive licensing, well-structured availability, and large size. ISIC archive is currently the standard source for dermatoscopic image analysis research. Note however, it tends to be biased towards melanocytic lesions. The HAM10000 dataset released was originally from ISIC archive (6). Because there are limitation of available datasets, biased research analysis toward melanocytic lesions and disregarded non-melanocytic lesions were prevalent in the past. The mismatch between the small diversity of available training data and the variety of real life data resulted in a moderate performance of automated diagnostic systems in the clinical setting even though excellent performance in experimental settings were observed (7,8) Building a classifier for multiple diseases are relatively more challenging compare to that of the binary classification (9). Currently, reliable multi-class predictions are only available for clinical images of skin diseases but not yet available for dermatoscopic images (10,11)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iiXcECVnDNmL"
      },
      "source": [
        "## Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hlKeHx0Zn1xG"
      },
      "source": [
        "The dataset utilized in this project is HAM10000 (“Human Against Machine with 10000 training images”), it consists of 10015 dermatoscopic images. The labels are essentially the seven diagnostic categories of the skin tumors, of which 5 are benign and 2 are malignant. The malignant tumors are basal cell carcinoma (BCC) and melanoma (MEL) respectively. Benign  tumors are AKIEC, BKL, DF, NV, VASC. A metadata file with variables lesion_id, image_id, dx,dx_type, age, sex and localization can be obtained from the following link: https://www.kaggle.com/datasets/surajghuwalewala/ham1000-segmentation-and-classification. Lesion id corresponds to the patient case id, Image id is the specific patient specimen id, Dx is the diagnosis of the skin lesion, Dx type is the diagnostic categories such as histopathology or follow up, age is the age of the patient, sex is the gender of the patient and localization is the area presence of the skin lesion on patient body. The HAM10000 dataset was originally from the International Skin Imaging Collaboration archive, which is the standard source for dermatoscopic image analysis research. The data appeared in a 2018 challenge, with the goal of enhancing diagnostic accuracy for distinguishing melanoma from other skin abnormalities and tumors. We want to make sure that our models are sensitive to these malignant tumor detection. Also note, Melanocytic nevi is a benign tumor label, it dominates the majority of our dataset, as we will see in the EDA section. Some detailed description for the labels are included below for references:\n",
        "\n",
        "\n",
        "Actinic keratoses and intraepithelial carcinoma / Bowen's disease (AKIEC): Common non-invasive, variants of squamous cell carcinoma that can be treated locally without surgery. Actinic keratoses are more common on the face and Bowen’s disease is more common on other body sites. Induced by UV-light or human papilloma virus infection.\n",
        "\n",
        "Basal cell carcinoma (BCC) Common variant of epithelial skin cancer that rarely metastasizes but grows destructively if untreated. \n",
        "\n",
        "Benign keratosis-like lesions (solar lentigines / seborrheic keratoses and lichen-planus like keratoses, BKL) \"Benign keratosis\" is a generic class that include three subgroups, may look different dermatoscopically, they are similar biologically and often reported under the same generic term histopathologically. \n",
        "\n",
        "Dermatofibroma (DF) Benign skin lesion regarded as either a benign proliferation or an inflammatory reaction to minimal trauma. \n",
        "\n",
        "Melanocytic nevi (NV) Benign neoplasms of melanocytes \n",
        "\n",
        "Melanoma (MEL) Malignant neoplasm derived from melanocytes that may appear in different variants. If excised in an early stage it can be cured by simple surgical excision.\n",
        "\n",
        "Vascular lesions (angiomas, angiokeratomas, pyogenic granulomas and hemorrhage, VASC). Vascular skin lesions: cherry angiomas, angiokeratomas and pyogenic granulomas, hemorrhage.\n",
        "\n",
        "In the data cleaning phase, after loading in the metadata and inspecting it using df.info(), some age entries are null, 9958 non-null compared to 10015 non-null for all other attributes. To resolve this, fill the null values with the average of the age column and change the type to integer. Checking again using df.isnull().sum() yields no missing values for any columns. Check to verify if the age column has any abnormal values by seeing the absolute minimum and maximum of the patient age using: [df['age'].min(),df['age'].max()], the minimum is 0 and maximum is 85. Therefore, no abnormal values were detected in the age column.  Next, print out all the unique values of each variable relevant to the patient. Two abnormal result were seen, sex column have values ['male' 'female' 'unknown'], and localization column have values ['scalp' … 'unknown' ... 'acral']. Unknown sex and unknown localization do not contribute any values to our further analysis, remove all the rows with either unknown localization or sex, this yields 9771 rows, which is 244 rows less compare to the original dataset, this is fine because we are dropping 2.4% of the original dataset. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dSiUHP37D9VW"
      },
      "source": [
        "## Methods"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j0odSw51D4HX"
      },
      "source": [
        "In the exploratory data analysis phase, we want to visualize data, detect errors and outliers, discover relationships and patterns. To do this, we implemented both univariate analysis and bivariate analysis. In univariate analysis, we want to observe the frequency or count of each subcategory to a variable of interest. In all,  most patients screened for skin tumors are in the age of 30-60. That is, the histogram presented a slightly normal distribution look, this may imply that most abnormal looking skin lesions appeared around age 40 to 45 for an individual and need to be checked out to see if the skin lesion is normal. There are also slightly higher male patients presenting a skin lesion compared to female patients in the dataset. The top 5 skin lesion localization areas are the back, lower extremity, trunk, upper extremity and abdomen. The majority of the diagnosis for skin lesions are melanocytic nevi or NV, which is a benign neoplasm of melanocytes. A pie chart was created to illustrate this point, with 66.5% of the labels being NV. This contributes to imbalanced labels or dataset and can affect our later model and metric analysis. Additionally, the majority of the diagnosis type for skin lesions in the dataset are either histopathology or follow-up, this makes sense because dermatologist or pathologist’s microscopic interpretation remain the gold standard for detecting skin cancer. In bivariate analysis, if the count of each skin lesion diagnosis is compared with the localization area, we can conclude that a lot of the skin tumors were NV and the most likely presentation area of the skin tumors are back, trunk, upper and lower extremity and abdomen. In describing the diagnosis pertaining to age groups, we can see that NV diagnosis follows pretty much a standard normal distribution with respect to increase in age. But in regard to other skin tumor conditions, with age increasing, the count of other types of skin tumor are more frequently seen. This is expected because cancer is essentially mutation accumulation as an individual ages, such genetic alteration either expresses cell proliferation or stops or reduces tumor suppressor gene regulators, or both. Finally, with regard to diagnosis in different genders, NV is the most common tumor diagnosis for both men and women, and the other tumor diagnosis is pretty much proportional in both men and women.\n",
        "\n",
        "\n",
        "The workflow for our pipeline started with extracting data from the database. Then we will perform EDA and data cleaning on the raw data. Afterward, we will go through a series of data preprocessing procedures. The data preprocessing procedures contain undersampling, normalize/rescale, train test split, data augmentation and weight calculation. Next, we will conduct test runs on multiple machine learning models and select the best performing model to proceed further. Later we will tune the hyperparameter for the model and train the model. At last, we will evaluate the model and decide if we are going to go back previous steps or save the trained model.\n",
        "\n",
        "From the above EDA section, we mentioned above that one of the bigger issues with our data set is that it is imbalanced with the type of labels it has. About 67% of the data belong to “nv” and only about 11.1% and 5.1% to “mel” and “bcc”, the two cancer cells we are interested in. This will cause a problem for us. With this data set our model will favor the majority in training due to its high frequent appearance and cause less resources to be allocated to two cancer cells that we want to focus on. To accommodate this issue, we incorporated undersample, data augmentation and weight calculation into data preprocessing. Undersample will decrease the amount of sample for majority that use in model training. Data augmentation will generate new images for targeted images through rotation and translation. Weight calculation will generate a dictionary that each skin lesion label is corresponding to a number that represents the weight that each particular label will contribute in loss calculation during model training. The fundamental logic behind these techniques is to balance the loss calculation in model training for labels through either balancing the data set by changing  the proportion of each label or enhancing the weight of labels with smaller sample size. These techniques were quite effective in our experiment especially undersampling the majority size. For example, mel’s F1 score increased from 0.53 to 0.67 when we decreased the size for nv from 6000 to 1500.\n",
        "\n",
        "The normalize/rescale step in the preprocessing was to divide the image data pixel by 255 to normalize the image data. The normalized image data will reduce the value in each pixel to between 0 to 1. This will make the computation more efficient and stable. However, we will not rescale the data for model implement EfficientNet since EfficientNet models expect the inputs to be float tensors of pixels with values in the [0-255] range. The train test split was used to split the data into training data and testing data. It is important that we split the data before the data augmentation. We want to make sure that the data we use for testing is never seen by the trained model. We also applied principle component analysis (PCA) for our data. The amount of features for image data is huge since each pixel represents a feature. After putting our data through PCA we were able to reduce the amount of features from 24320 to 632 with 99% variance retained. However, this process will not work for convolutional neural networks since we are required to input the image data as an actual image structure for the model.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W15I-ipREA7Q"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TtAGw2B4Dnz4"
      },
      "source": [
        "In this project we do early test runs on multiple models and evaluate their validation accuracy, mel’s F1 score, bcc’s F1 score and the difference between training accuracy and validation accuracy. The validation accuracy is to measure the general performance. Mel’s and bcc’s scores are used to measure the model’s performance on distinguishing these two cancer cells. The difference between training accuracy and validation accuracy is to measure the degree of overfitting of the model after training. The higher the difference the more overfit the model is. The models that we included in the test runs are the ridge classifier, logistic classifier, support vector classifier, random forest classifier, dense neural network(DNN), convolutional neural network(CNN) and CNN with EfficientNet.\n",
        "\n",
        "All the models are tested on the same data set. Per the result of the test runs, we found that CNN with EfficientNet is having the best performance. It has the highest validation accuracy, mel’s F1 score and bcc’s F1 score. Although, it has the second difference for training accuracy and validation accuracy, but its F1 score for the two cancer skin cell suggest its potential for being the best model. Therefore, we picked the EfficientNet model to be our model for further tuning and training.\n",
        "\n",
        "After tuning and series of training, we will give a detailed evaluation for our final model. From the Learning Curve - Accuracy graph we noticed that the validation accuracy topped around 20 epochs and the gap between validation accuracy and training accuracy started widening after 5 epochs. The huge difference between validation accuracy and training accuracy indicated overfitting in our model. The Learning Curve - Loss told the same story as the gap between two curves started widening around 5 epochs and continued to remain a gap between the curves. The confusion matrix showed that our model got 512 correct out of 722 total labels. It is about 71% accuracy, which is significantly lower than our early test run on the model during model selection. This is because the undersample of the majority, data augmentation of the cancer cells and the weight application on model had made the model to allocate more resources to other labels than the majority. As the labels were evenly distributed in the data set, it became harder for the model to achieve high accuracy with just doing well on distinguishing single labels. On the other hand, the performance on other labels were all improved due to the balance of the data set. The F1 score for mel and bcc had improved from 0.55 and 0.62 to 0.65 and 0.70 respectively. This demonstrated that our strategies in data preprocessing procedures had worked as we expected. The goal for this project was to build a model that matches or beats the human benchmark on diagnosing skin cancers. The F1 score for the two cancer cells told us that our model fell within the lower range of the human benchmark using 90 x 90 pixel images.\n",
        "\n",
        "We took a step further to see if we can improve our model by applying the one vs. all technique on the two cancer cells. The one vs. all technique will change the problem from a multi-class classification problem to a binary classification problem. The labels for mel and bcc will be updated to 1 in each of their own one vs. all training and all other labels will be 0. This will help our model to focus on distinguishing the two cancer cells from all other skin lesions. The confusion matrix and the classification report suggested that the one vs. all strategy worked well on bcc but not mel. The F1 score for bcc was improved from 0.70 to 0.75, where the F1 score for mel was actually dropped from 0.65 to 0.64. We also trained our model with higher resolution images (240 x 240 pixels). We expected our model performance to improve as higher resolution images will provide great details for the model. The learning curve graph for the model showed an overall improvement on model accuracy. Although the overfitting issue persisted, the difference between validation accuracy and training accuracy dropped from 29% to 21%. The confusion matrix showed that mel’s accuracy improved from 97/153 to 122/153 and pcc’s accuracy improved from 57/79 to 62/79. The F1 score for the two cancer cells also significantly improved per classification report. The F1 score improved to 0.73 and 0.77 respectively for mel and bcc. The F1 scores suggested that our model fell within the higher end of the human benchmark when using higher resolution images."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c-JCM5WQEJIj"
      },
      "source": [
        "## Conclusion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u3r4DzmO_d_7"
      },
      "source": [
        "In conclusion, our data preprocessing technique of down sample, data augmentation and applying weight were quite effective according to experiment data. They significantly improved the F1 scores for the two cancer cells. The model we built had matched our goal for the project. It fell within the lower end of the human benchmark if using 90 x 90 pixels images and higher end if using 240 x 240 pixels images. We also found that age and localization were surprisingly effective in our model training. They almost improved all models in every evaluation aspect. Our research also showed that one vs all technique improved bcc’s F1 score but not mel. However, like all other research, there were limitations in our project, we noticed that our data set only contained patients with lighter skin. This may cause our model to suffer from biases. Also we only had limited risk factor features. If more features are available such as family history and pre-existing conditions, we can further improve our model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0nla5RmBELYF"
      },
      "source": [
        "## Attribution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zv8Y3nzNENl6"
      },
      "source": [
        "## Bibliography\n",
        "1. Rosendahl, C., Tschandl, P., Cameron, A. & Kittler, H. Diagnostic accuracy of dermatoscopy for melanocytic and nonmelanocytic pigmented lesions. J Am Acad Dermatol 64, 1068–1073 (2011).\n",
        "\n",
        "2. Bechelli S, Delhommelle J. Machine Learning and Deep Learning Algorithms for Skin Cancer Classification from Dermoscopic Images. Bioengineering (Basel). 2022;9(3):97. Published 2022 Feb 27.\n",
        "\n",
        "3. Binder, M. et al. Application of an artificial neural network in epiluminescence microscopy pattern analysis of pigmented skin lesions: a pilot study. Br J Dermatol 130, 460–465 (1994).\n",
        "\n",
        "4. Codella, N. C. F. et al. Skin Lesion Analysis Toward Melanoma Detection: A Challenge at the 2017 International Symposium on Biomedical Imaging (ISBI), Hosted by the International Skin Imaging Collaboration (ISIC). Preprint at https://arxiv.org/abs/1710.05006 (2017).\n",
        "\n",
        "5. Deng, J. et al. ImageNet: A large-scale hierarchical image database, 2009 IEEE Conference on Computer Vision and Pattern Recognition, Miami, FL, 2009, pp. 248–255 (2009).\n",
        "\n",
        "6. Tschandl, P., Rosendahl, C. & Kittler, H. The HAM10000 dataset, a large collection of multi-source dermatoscopic images of common pigmented skin lesions. Sci Data 5, 180161 (2018). \n",
        "\n",
        "7. Dreiseitl, S., Binder, M., Hable, K. & Kittler, H. Computer versus human diagnosis of melanoma: evaluation of the feasibility of an automated diagnostic system in a prospective clinical trial. Melanoma Res 19, 180–184 (2009).\n",
        "\n",
        "8. Kharazmi, P., Kalia, S., Lui, H., Wang, Z. J. & Lee, T. K. A feature fusion system for basal cell carcinoma detection through data-driven feature learning and patient profile. Skin Res Technol 24, 256–264 (2017).\n",
        "\n",
        "9. Sinz, C. et al. Accuracy of dermatoscopy for the diagnosis of nonpigmented cancers of the skin. J Am Acad Dermatol 77, 1100–1109 (2017).\n",
        "\n",
        "10. Esteva, A. et al. Dermatologist-level classification of skin cancer with deep neural networks. Nature 542, 115–118 (2017).\n",
        "\n",
        "11. Han, S. S. et al. Classification of the clinical images for benign and malignant cutaneous tumors using a deep learning algorithm. J Invest Dermatol, Preprint at https://doi.org/10.1016/j.jid.2018.01.028 (2018)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bCiq2HXwEPsH"
      },
      "source": [
        "## Appendix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SYqapfKhERjm"
      },
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "draft_Final_Report.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}