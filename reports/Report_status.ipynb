{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nJJsTWN6FtuX"
   },
   "source": [
    "# New Era Of Data Pathologist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ktDHhg5TFuaa"
   },
   "source": [
    "Abstract:\n",
    "\n",
    "Skin cancer misdiagnosis by dermatologists is not uncommon. 25-33% of the skin cancers are incorrectly diagnosed as eczema or another less serious disease. Ultimately, the problem would lead us to ask whether machine learning models can be designed and implemented and to the extent which model can effectively classify if a patient developed skin cancer based on photographs of skin lesions on dermatologic slides. Early skin maligicancy is important because screening for earlier skin cancer detection remains limited, which leads to late diagnoses in most cases. Accurate skin cancer detection at earlier stage in patients show improved survival, clinical outcomes, and quality of life. \n",
    "Discoveries: 2-3\n",
    "Linear -logistics\n",
    "SVM\n",
    "DNN/CNN\n",
    "\n",
    "\n",
    "Introduction:\n",
    "\n",
    "The research question for this project is: can machine learning models be designed and implemented to effectively classify if a patient developed skin cancer based on photographs of skin lesions on dermatologic slides. To the extent which model serves the best in classifying skin leisions as benign and malignant using series of metrics. Early skin maligicancy is important because screening for earlier skin cancer detection remains limited, which leads to late diagnoses in most cases. Accurate skin cancer detection at earlier stage in patients by dermatologists and pathologists show improved survival, clinical outcomes, and quality of life. Research plan includes initial exploratory data analysis to investigate data patterns,anomalies, and to test hypothesis and to check assumptions with the help of summary statistics and graphical representations. We will develop basic linear and logistic models, SVM, DNN, CNN models. We did not achieve high linear and logistic model accuracy, CNN accuracy was higher than the DNN. SVM - still attempting. Data cleaning includes fill in missing age column with the average for the age column, we also detected that the data labels are imbalanced due to the fact that skin cancers are rare occurence relative to the overal general population. Therefore, initial data cleaning and preparation allows us to develop approches in combating data imblance, such as resampling techniques. \n",
    "\n",
    "\n",
    "\n",
    "Background:\n",
    "\n",
    "Dermatoscopy is the predominant gold standard diagnostic technique that helps in the diagnosis of benign and malignant skin lesions in comparison to examination with the unaided eye(1). Dermatoscopic images are great available source to train artificial neural networks to categorize the skin lesions automatically. Binder and his colleagues have long demonstrated such technique to differentiate melanomas from melanocytic nevi, dating back to 1994 (2). Interestingly, the study suffered from small sample size but managed to obtain promising results. Recent advancement in the complexity of neural networks in machine learning techniques is bringing hope that automated diagnostic systems will one day work synchronously or asynchronously with expertise skills to improve the diagnosis accuracy (3).\n",
    "\n",
    "Training of neural-network based diagnostic algorithms requires a large number of annotated images but the number of high quality dermatoscopic images with reliable diagnoses is limited or restricted to only a few classes of diseases.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Data:\n",
    "\n",
    "The dataset utilizaed in this project is HAM10000 (“Human Against Machine with 10000 training images”), it consists of 10015 dermatoscopic images. Seven diagnostic categories (Actinic keratoses and intraepithelial carcinoma / Bowen's disease (AKIEC), basal cell carcinoma (BCC),benign keratosis-like lesions (solar lentigines / seborrheic keratoses and lichen-planus like keratoses, BKL),dermatofibroma (DF), melanoma (MEL), melanocytic nevi (NV), vascular lesions (angiomas, angiokeratomas, pyogenic granulomas and hemorrhage, VASC) and a metadata file with variables lesion_id, image_id, dx,dx_type, age and localization can be obtained from the following link: https://www.kaggle.com/datasets/surajghuwalewala/ham1000-segmentation-and-classification. \n",
    "You can begin discussing the data wrangling, and data cleaning. Some EDA may happen here. This includes your data source (including URL if applicable), any articles behind the data source.\n",
    "\n",
    "\n",
    "Methods:\n",
    "\n",
    "How did you take your data and set up the problem? Describe things like normalization, feature selection, the models you chose. In this section, you may have EDA and graphs showing the exploration of hyper-parameters. Note: Use graphs to illustrate interesting relationships that are important to your final analyses. DO NOT just show a bunch of graphs because you can. You should label and discuss every graph you include. There is no required number to include. The graphs should help us understand your analysis process and illuminate key features of the data.\n",
    "\n",
    "Evaluation:\n",
    "\n",
    "\n",
    "Here you are going to show your different models’ performance. It is particularly useful to show multiple metrics and things like ROC curves (for binary classifiers). Make sure it is clearly not just what the score is but for which instances in the data one has the largest errors (in a regression), or just sample examples miss-classified. Make an attempt to interpret the parameters of the model to understand what was useful about the input data. Method comparison and sensitivity analyses are absolutely CRUCIAL to good scientific work. To that end, you MUST compare at least 2 different methods from class in answering your scientific questions. It is important to report what you tried but do so SUCCINCTLY.\n",
    "\n",
    "Conclusion:\n",
    "\n",
    "\n",
    "How well did it work? Characterize how robust you think the results are (did you have enough data?) Interpret of what the model found (what variables were useful, what was not)? Try to avoid describing what you would do if you had more time. If you have to make a statement about “future work” limit it to one short statement.\n",
    "\n",
    "Attribution:\n",
    "\n",
    "\n",
    "Using the number and size of GitHub commits by the author (bar graph), and the git hub visualizations of when the commits occurred. Using these measures each person should self-report how many code-hours of their work are visible in the repo with 2-3 sentences listing their contribution. Do not report any code hours that cannot be traced to commits. If you spend hours on a 2-line change of code or side-reading you did, you cannot report. If you do searches or research for the project that does not result in code, you must create notes in a markdown file (eg. in the project wiki) and the notes should be commensurate with the amount of work reported. Notes cannot be simply copy-pasted from elsewhere (obviously).\n",
    "\n",
    "Bibliography:\n",
    "\n",
    "1. Rosendahl, C., Tschandl, P., Cameron, A., & Kittler, H. (2011). Diagnostic accuracy of dermatoscopy for melanocytic and nonmelanocytic pigmented lesions. Journal of the American Academy of Dermatology, 64(6), 1068–1073. https://doi.org/10.1016/j.jaad.2010.03.039\n",
    "\n",
    "2. Binder, M., Steiner, A., Schwarz, M., Knollmayer, S., Wolff, K., & Pehamberger, H. (1994). Application of an artificial neural network in epiluminescence microscopy pattern analysis of pigmented skin lesions: a pilot study. The British journal of dermatology, 130(4), 460–465. https://doi.org/10.1111/j.1365-2133.1994.tb03378.x\n",
    "\n",
    "3. Codella, N. C. F. et al. Skin Lesion Analysis Toward Melanoma Detection: A Challenge at the 2017 International Symposium on Biomedical Imaging (ISBI), Hosted by the International Skin Imaging Collaboration (ISIC). Preprint at https://arxiv.org/abs/1710.05006 (2017).\n",
    "\n",
    "References should appear at the end of the report/notebook. Again, no specific format is required but be consistent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "1Report.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
